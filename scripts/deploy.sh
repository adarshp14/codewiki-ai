#!/bin/bash

echo "üöÄ CodeWiki AI - UNIFIED Deployment (Backend + Ollama)"
echo "====================================================="
echo ""
echo "‚ú® NEW: Both FastAPI backend AND Ollama run together on Render!"
echo ""

echo "üîë STEP 1: GET API KEYS"
echo "======================"
echo ""
echo "Google Gemini API (Required):"
echo "  üîó https://makersuite.google.com/app/apikey"
echo ""
echo "OpenAI API (Optional):"
echo "  üîó https://platform.openai.com/api-keys"
echo ""

echo "üêç STEP 2: DEPLOY BACKEND + OLLAMA (Render - FREE)"
echo "================================================="
echo ""
echo "üöÄ UNIFIED DEPLOYMENT: FastAPI + Ollama in one container!"
echo ""
echo "1. Go to: https://dashboard.render.com/"
echo "2. Sign up with GitHub"
echo "3. Click 'New +' ‚Üí 'Web Service'"
echo "4. Connect: https://github.com/adarshp14/codewiki-ai"
echo "5. Configure:"
echo "   - Name: codewiki-ai-backend"
echo "   - Runtime: Docker"
echo "   - Dockerfile Path: ./Dockerfile.render"
echo "   - Auto-Deploy: Yes"
echo "6. Environment Variables:"
echo "   - GOOGLE_API_KEY: [your-api-key]"
echo "   - CORS_ORIGINS: https://codewiki-ai.vercel.app"
echo "   - NODE_ENV: production"
echo ""
echo "‚úÖ This will automatically:"
echo "   - Install and start Ollama"
echo "   - Pull nomic-embed-text and llama2:7b models"
echo "   - Start FastAPI backend"
echo "   - All in one free Render container!"
echo ""

echo "üì¶ STEP 3: DEPLOY FRONTEND (Vercel - FREE)"
echo "=========================================="
echo ""
echo "1. Install Vercel CLI: npm install -g vercel"
echo "2. Login: vercel login"
echo "3. Deploy: vercel"
echo "4. Set environment:"
echo "   vercel env add NEXT_PUBLIC_API_URL"
echo "   Value: https://codewiki-ai-backend.onrender.com"
echo "5. Production deploy: vercel --prod"
echo ""

echo "üåê YOUR DEPLOYMENT URLS"
echo "======================="
echo ""
echo "Frontend: https://codewiki-ai.vercel.app"
echo "Backend:  https://codewiki-ai-backend.onrender.com"
echo "Health:   https://codewiki-ai-backend.onrender.com/health"
echo "Ollama:   https://codewiki-ai-backend.onrender.com/ollama/status"
echo ""
echo "üí∞ Total Cost: \$0.00 (100% FREE!)"
echo ""
echo "üéâ Benefits of Unified Deployment:"
echo "   ‚úÖ No separate Ollama setup needed"
echo "   ‚úÖ All AI models run on Render (free tier)"
echo "   ‚úÖ FastAPI + Ollama in same container"
echo "   ‚úÖ Automatic model downloading"
echo "   ‚úÖ Health checks for both services"
echo ""
echo "üìö Need help? Check: https://github.com/adarshp14/codewiki-ai"